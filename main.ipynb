{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from dataTransformation import labels4clients, distribute_data_labels4clients\n",
    "from gan_model import Discriminator, Generator, initialize_weights\n",
    "from network import Server, Worker\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import Logger\n",
    "from fid_score import *\n",
    "from inception import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "BATCH_SIZE = 64\n",
    "NOISE_DIM = 128\n",
    "NUM_EPOCHS = 50\n",
    "fid_batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0], 1: [0], 2: [0], 3: [0], 4: [0], 5: [0], 6: [0], 7: [0], 8: [0], 9: [0]}\n"
     ]
    }
   ],
   "source": [
    "num_workers = 1\n",
    "num_unique_users = num_workers\n",
    "num_classes = 10\n",
    "classes_per_user = 10\n",
    "\n",
    "logger = Logger(model_name='F2U',data_name='CIFAR10')\n",
    "dictionary = labels4clients(num_classes,classes_per_user,num_workers,num_unique_users,False)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# trans_cifar = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.CIFAR10(root='./datasets/cifar/', train=True, download=True, transform=trans_cifar)\n",
    "dataset_test = datasets.CIFAR10(root='./datasets/cifar/', train=False, download=True, transform=trans_cifar)\n",
    "dataloader_one = torch.utils.data.DataLoader(dataset, shuffle = True,batch_size=BATCH_SIZE)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, shuffle = False,batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in dataloader_test:\n",
    "    test_imgs=img[0].to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.data[0])\n",
    "# print(dataset.transforms(dataset.data[0],transforms.ToTensor()))\n",
    "# print(dataset.transforms(dataset.data[0],trans_cifar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
       "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
       "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
       "         ...,\n",
       "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
       "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
       "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
       "\n",
       "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
       "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
       "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
       "         ...,\n",
       "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
       "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
       "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
       "\n",
       "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
       "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
       "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
       "         ...,\n",
       "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
       "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
       "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "print(normalized)\n",
    "trans_cifar(dataset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.data.shape)\n",
    "# print(type(dataset))\n",
    "# print(dataloader_one.dataset.data.shape)\n",
    "# x,_ = dataloader_one.dataset[0]\n",
    "# print(x.shape)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized_np = np.empty((dataset.data.shape[0],dataset.data.shape[3],dataset.data.shape[1],dataset.data.shape[2]))\n",
    "for i in range(len(dataset)):\n",
    "    x_train_normalized_np[i] = trans_cifar(dataset.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(dataset.data)\n",
    "y_train = np.asarray(dataset.targets)\n",
    "x_clinet_list, y_client_list = distribute_data_labels4clients(x_train_normalized_np,y_train,dictionary,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDist(y,num_classes,user_num):\n",
    "    ax = sns.countplot(x=y)\n",
    "    ax.set(title=\"Count of data classes for %s\" %user_num)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (len(x_clinet_list)):\n",
    "    print(len(y_client_list[i]))\n",
    "    getDist(y_client_list[i],num_classes,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "dev = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_model = InceptionV3().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG = Generator().to(dev)\n",
    "# netD = Discriminator().to(dev)\n",
    "# summary(netG,(128,1,1))\n",
    "# summary(netD,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_server = Server(0,LEARNING_RATE)\n",
    "main_server.generator.train()\n",
    "workers = []\n",
    "for i in range(num_workers):\n",
    "    worker = Worker(i,LEARNING_RATE)\n",
    "    # x_clinet_list[i] = np.transpose(x_clinet_list[i],(0, 3, 1, 2))\n",
    "    worker.load_worker_data(x_clinet_list[i], y_client_list[i])\n",
    "    worker.discriminator.train()\n",
    "    workers.append(worker)\n",
    "    \n",
    "# summary(main_server.generator,(128,1,1))\n",
    "# summary(workers[0].discriminator,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "fixed_noise = torch.randn(36, NOISE_DIM, 1, 1).to(dev)\n",
    "\n",
    "worker_loaders = []\n",
    "\n",
    "for worker in workers:\n",
    "    # print(worker.x_data.shape)\n",
    "    worker_loaders.append([])\n",
    "    for batch_id, real in enumerate(DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE)):\n",
    "        worker_loaders[-1].append(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/782                  Loss D: 0.4976, loss G: 0.7430, FID Score: 409.2\n",
      "Epoch [0/50] Batch 100/782                  Loss D: 0.0202, loss G: 1.0473, FID Score: 492.4\n",
      "Epoch [0/50] Batch 200/782                  Loss D: 0.0140, loss G: 1.0317, FID Score: 445.3\n",
      "Epoch [0/50] Batch 300/782                  Loss D: 0.0167, loss G: 1.0087, FID Score: 424.2\n",
      "Epoch [0/50] Batch 400/782                  Loss D: 0.0227, loss G: 0.9668, FID Score: 394.7\n",
      "Epoch [0/50] Batch 500/782                  Loss D: 0.0279, loss G: 1.0672, FID Score: 439.1\n",
      "Epoch [0/50] Batch 600/782                  Loss D: 0.0227, loss G: 1.0143, FID Score: 408.2\n",
      "Epoch [0/50] Batch 700/782                  Loss D: 0.0125, loss G: 1.0008, FID Score: 495.2\n",
      "Epoch [1/50] Batch 0/782                  Loss D: 0.0178, loss G: 1.0119, FID Score: 484.6\n",
      "Epoch [1/50] Batch 100/782                  Loss D: 0.0218, loss G: 0.9984, FID Score: 450.8\n",
      "Epoch [1/50] Batch 200/782                  Loss D: 0.0166, loss G: 1.0150, FID Score: 404.0\n",
      "Epoch [1/50] Batch 300/782                  Loss D: 0.0183, loss G: 0.9185, FID Score: 398.7\n",
      "Epoch [1/50] Batch 400/782                  Loss D: 0.0117, loss G: 1.0345, FID Score: 410.6\n",
      "Epoch [1/50] Batch 500/782                  Loss D: 0.3840, loss G: 0.6643, FID Score: 384.0\n",
      "Epoch [1/50] Batch 600/782                  Loss D: 0.0453, loss G: 0.9308, FID Score: 421.5\n",
      "Epoch [1/50] Batch 700/782                  Loss D: 0.0287, loss G: 0.9592, FID Score: 563.2\n",
      "Epoch [2/50] Batch 0/782                  Loss D: 0.1298, loss G: 0.5776, FID Score: 381.8\n",
      "Epoch [2/50] Batch 100/782                  Loss D: 0.0610, loss G: 0.8618, FID Score: 503.6\n",
      "Epoch [2/50] Batch 200/782                  Loss D: 0.0387, loss G: 0.9353, FID Score: 404.8\n",
      "Epoch [2/50] Batch 300/782                  Loss D: 0.0882, loss G: 0.8983, FID Score: 358.2\n",
      "Epoch [2/50] Batch 400/782                  Loss D: 0.0907, loss G: 0.7914, FID Score: 490.8\n",
      "Epoch [2/50] Batch 500/782                  Loss D: 0.0369, loss G: 1.1136, FID Score: 396.6\n",
      "Epoch [2/50] Batch 600/782                  Loss D: 0.0420, loss G: 1.0142, FID Score: 355.5\n",
      "Epoch [2/50] Batch 700/782                  Loss D: 0.0368, loss G: 0.9943, FID Score: 363.7\n",
      "Epoch [3/50] Batch 0/782                  Loss D: 0.0505, loss G: 0.8796, FID Score: 368.4\n",
      "Epoch [3/50] Batch 100/782                  Loss D: 0.0918, loss G: 1.0485, FID Score: 393.7\n",
      "Epoch [3/50] Batch 200/782                  Loss D: 0.0891, loss G: 0.7164, FID Score: 353.9\n",
      "Epoch [3/50] Batch 300/782                  Loss D: 0.1211, loss G: 1.0383, FID Score: 384.8\n",
      "Epoch [3/50] Batch 400/782                  Loss D: 0.0786, loss G: 0.7276, FID Score: 328.1\n",
      "Epoch [3/50] Batch 500/782                  Loss D: 0.0730, loss G: 0.8822, FID Score: 326.1\n",
      "Epoch [3/50] Batch 600/782                  Loss D: 0.0916, loss G: 0.8595, FID Score: 270.4\n",
      "Epoch [3/50] Batch 700/782                  Loss D: 0.1235, loss G: 0.7785, FID Score: 347.5\n",
      "Epoch [4/50] Batch 0/782                  Loss D: 0.0588, loss G: 1.0540, FID Score: 402.0\n",
      "Epoch [4/50] Batch 100/782                  Loss D: 0.0668, loss G: 0.8479, FID Score: 382.7\n",
      "Epoch [4/50] Batch 200/782                  Loss D: 0.1027, loss G: 0.7947, FID Score: 327.4\n",
      "Epoch [4/50] Batch 300/782                  Loss D: 0.1330, loss G: 0.7154, FID Score: 320.4\n",
      "Epoch [4/50] Batch 400/782                  Loss D: 0.0877, loss G: 1.0317, FID Score: 311.7\n",
      "Epoch [4/50] Batch 500/782                  Loss D: 0.0613, loss G: 1.0150, FID Score: 318.0\n",
      "Epoch [4/50] Batch 600/782                  Loss D: 0.0682, loss G: 0.7771, FID Score: 284.0\n",
      "Epoch [4/50] Batch 700/782                  Loss D: 0.0892, loss G: 0.7294, FID Score: 297.6\n",
      "Epoch [5/50] Batch 0/782                  Loss D: 0.0573, loss G: 0.9587, FID Score: 295.3\n",
      "Epoch [5/50] Batch 100/782                  Loss D: 0.0593, loss G: 1.1904, FID Score: 360.1\n",
      "Epoch [5/50] Batch 200/782                  Loss D: 0.0834, loss G: 0.9739, FID Score: 292.1\n",
      "Epoch [5/50] Batch 300/782                  Loss D: 0.0937, loss G: 0.9281, FID Score: 270.7\n",
      "Epoch [5/50] Batch 400/782                  Loss D: 0.1366, loss G: 0.6082, FID Score: 261.8\n",
      "Epoch [5/50] Batch 500/782                  Loss D: 0.1504, loss G: 0.8217, FID Score: 277.3\n",
      "Epoch [5/50] Batch 600/782                  Loss D: 0.1086, loss G: 1.0436, FID Score: 312.7\n",
      "Epoch [5/50] Batch 700/782                  Loss D: 0.0861, loss G: 0.7399, FID Score: 305.0\n",
      "Epoch [6/50] Batch 0/782                  Loss D: 0.0529, loss G: 0.8059, FID Score: 250.8\n",
      "Epoch [6/50] Batch 100/782                  Loss D: 0.0614, loss G: 0.8527, FID Score: 313.9\n",
      "Epoch [6/50] Batch 200/782                  Loss D: 0.0844, loss G: 1.0576, FID Score: 244.6\n",
      "Epoch [6/50] Batch 300/782                  Loss D: 0.0556, loss G: 0.9757, FID Score: 293.5\n",
      "Epoch [6/50] Batch 400/782                  Loss D: 0.0817, loss G: 0.8547, FID Score: 248.1\n",
      "Epoch [6/50] Batch 500/782                  Loss D: 0.0900, loss G: 0.9792, FID Score: 359.6\n",
      "Epoch [6/50] Batch 600/782                  Loss D: 0.0856, loss G: 0.9605, FID Score: 302.2\n"
     ]
    }
   ],
   "source": [
    "# GAN archicture trial\n",
    "start = 50\n",
    "end = start + NUM_EPOCHS\n",
    "for epoch in range(start,end):\n",
    "    for i, data in enumerate(dataloader_one):\n",
    "        worker = workers[0]\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "        fake = main_server.generator(noise)\n",
    "        real, _ = data\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        \n",
    "        current_disc_real = worker.discriminator(real).reshape(-1)\n",
    "        # print('current discriminator real output', current_disc_real)\n",
    "        worker.loss_disc_real = criterion(current_disc_real, torch.ones_like(current_disc_real))\n",
    "        # print('worker loss_disc_real output', current_disc_real)\n",
    "        current_disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "        worker.loss_disc_fake = criterion(current_disc_fake, torch.zeros_like(current_disc_fake))\n",
    "        worker.loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "        worker.discriminator.zero_grad()\n",
    "        worker.loss_disc.backward()\n",
    "        # total_norm_d =0\n",
    "        # for p in list(filter(lambda p: p.grad is not None, worker.discriminator.parameters())):\n",
    "        #     total_norm_d += p.grad.detach().data.norm(2).item()** 2\n",
    "        # total_norm_d = total_norm_d ** 0.5\n",
    "\n",
    "        worker.d_optimizer.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        \n",
    "        output = worker.discriminator(fake).reshape(-1)\n",
    "        main_server.loss_gen = criterion(output, torch.ones_like(output))\n",
    "        main_server.generator.zero_grad()\n",
    "        main_server.loss_gen.backward()\n",
    "\n",
    "        # total_norm_g =0\n",
    "        # for p in list(filter(lambda p: p.grad is not None, main_server.generator.parameters())):\n",
    "        #     total_norm_g += p.grad.detach().data.norm(2).item()** 2\n",
    "        # total_norm_g = total_norm_g ** 0.5\n",
    "\n",
    "        main_server.g_optimizer.step()\n",
    "\n",
    "\n",
    "        logger.log(worker.loss_disc.item(),main_server.loss_gen.item(),worker.loss_disc_real, worker.loss_disc_fake,epoch,i,len(dataloader_one))\n",
    "\n",
    "        # Print loss\n",
    "        if i % 100 == 0:    \n",
    "            fid_z = torch.randn(fid_batch_size, NOISE_DIM, 1,1).to(dev)\n",
    "            gen_imgs = main_server.generator(fid_z.detach())\n",
    "            mu_gen, sigma_gen = calculate_activation_statistics(gen_imgs, fic_model, batch_size=fid_batch_size,cuda=True)\n",
    "            mu_test, sigma_test = calculate_activation_statistics(test_imgs[:fid_batch_size], fic_model, batch_size=fid_batch_size)\n",
    "            fid = calculate_frechet_distance(mu_gen, sigma_gen, mu_test, sigma_test)\n",
    "            logger.log_fid(fid,epoch,i,len(dataloader_one))\n",
    "\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {i}/{len(dataloader_one)} \\\n",
    "                 Loss D: {worker.loss_disc:.4f}, loss G: {main_server.loss_gen:.4f}, FID Score: {fid:.1f}\"\n",
    "            )\n",
    "            # print(\n",
    "            #     f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {i}/{len(dataloader_one)} \\\n",
    "            #      Loss D: {worker.loss_disc:.4f}, loss G: {main_server.loss_gen:.4f}\"\n",
    "            # )\n",
    "\n",
    "        if i% 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = main_server.generator(fixed_noise)\n",
    "                logger.log_images(fake,len(fake), epoch, i, len(dataloader_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop for F2U\n",
    "start = 0\n",
    "end = start + NUM_EPOCHS\n",
    "for epoch in range(start,end):\n",
    "    for batch_id in range(len(worker_loaders[0])):\n",
    "\n",
    "        highest_loss = 0\n",
    "        chosen_discriminator = None\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "        fake = main_server.generator(noise)\n",
    "\n",
    "        for worker_id, worker in enumerate(workers):\n",
    "            current_worker_real = worker_loaders[worker_id][batch_id].float().to(dev)\n",
    "            # print(real.shape)\n",
    "\n",
    "            ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "            current_disc_real = worker.discriminator(current_worker_real).reshape(-1)\n",
    "            worker.loss_disc_real = criterion(current_disc_real, torch.ones_like(current_disc_real))\n",
    "            current_disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "            worker.loss_disc_fake = criterion(current_disc_fake, torch.zeros_like(current_disc_fake))\n",
    "            worker.loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "            worker.discriminator.zero_grad()\n",
    "            worker.loss_disc.backward()\n",
    "            worker.d_optimizer.step()\n",
    "            # print(worker.loss_disc_fake, i)\n",
    "            if highest_loss < worker.loss_disc_fake:\n",
    "                highest_loss = worker.loss_disc_fake\n",
    "                chosen_discriminator = worker_id\n",
    "        # print(f\"chosen worker is {chosen_discriminator} with loss of: {highest_loss.item():.4f}\")\n",
    "        chosen_worker = workers[chosen_discriminator]\n",
    "        \n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = chosen_worker.discriminator(fake).reshape(-1)\n",
    "        main_server.loss_gen = criterion(output, torch.ones_like(output))\n",
    "        main_server.generator.zero_grad()\n",
    "        main_server.loss_gen.backward()\n",
    "        main_server.g_optimizer.step()\n",
    "\n",
    "        logger.log(chosen_worker.loss_disc.item(),main_server.loss_gen.item(),chosen_worker.loss_disc_real, chosen_worker.loss_disc_fake,epoch,batch_id,len(worker_loaders[0]))\n",
    "\n",
    "        # Print loss\n",
    "        if batch_id % 100 == 0:\n",
    "            fid_z = torch.randn(fid_batch_size, NOISE_DIM, 1,1).to(dev)\n",
    "            gen_imgs = main_server.generator(fid_z.detach())\n",
    "            mu_gen, sigma_gen = calculate_activation_statistics(gen_imgs, fic_model, batch_size=fid_batch_size,cuda=True)\n",
    "            mu_test, sigma_test = calculate_activation_statistics(test_imgs[:fid_batch_size], fic_model, batch_size=fid_batch_size)\n",
    "            fid = calculate_frechet_distance(mu_gen, sigma_gen, mu_test, sigma_test)\n",
    "            logger.log_fid(fid,epoch,batch_id,len(worker_loaders[0]))\n",
    "\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_id}/{len(worker_loaders[0])} \\\n",
    "                 Loss D: {chosen_worker.loss_disc:.4f}, loss G: {main_server.loss_gen:.4f}, FID Score: {fid:.1f}\"\n",
    "            )\n",
    "        if batch_id% 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = main_server.generator(fixed_noise)\n",
    "                logger.log_images(fake,len(fake), epoch, batch_id, len(worker_loaders[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = []\n",
    "\n",
    "# for worker in workers:\n",
    "#     # print(worker.x_data.shape)\n",
    "#     dataloaders.append(DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE))\n",
    "\n",
    "# i = iter(dataloaders[0])\n",
    "# print(next(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "# NOISE_DIM = 128\n",
    "# fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(dev)\n",
    "# writer_real = SummaryWriter(f\"logs/real\")\n",
    "# writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "# step = 0\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     highest_loss = 0\n",
    "#     chosen_discriminator = None\n",
    "#     for i, worker in enumerate(workers):\n",
    "#         print(worker.x_data.shape)\n",
    "#         dataloader = DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE)\n",
    "#         for batch_id, real in enumerate(dataloader):\n",
    "#             real = real.float().to(dev)\n",
    "#             # print(real.shape)\n",
    "#             # print(real)\n",
    "#             noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "#             fake = main_server.generator(noise)\n",
    "\n",
    "#             ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "#             disc_real = worker.discriminator(real).reshape(-1)\n",
    "#             worker.loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "#             disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "#             worker.loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "#             loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "#             worker.discriminator.zero_grad()\n",
    "#             loss_disc.backward()\n",
    "#             worker.d_optimizer.step()\n",
    "#             if batch_id % 20 == 0:\n",
    "#                 print(\n",
    "#                     f\"Worker: {i} Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_id}/{len(dataloader)} \\\n",
    "#                         Loss D: {loss_disc:.4f}\"\n",
    "#                 )\n",
    "#         # print(worker.loss_disc_fake, i)\n",
    "#         if highest_loss < worker.loss_disc_fake:\n",
    "#             highest_loss = worker.loss_disc_fake\n",
    "#             chosen_discriminator = i\n",
    "#         print(f\"chosen worker is {chosen_discriminator} with loss of: {highest_loss.item()}\")\n",
    "#     dataloader = DataLoader(dataset=workers[chosen_discriminator].x_data,batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "    # output = disc(fake).reshape(-1)\n",
    "    # loss_gen = criterion(output, torch.ones_like(output))\n",
    "    # gen.zero_grad()\n",
    "    # loss_gen.backward()\n",
    "    # opt_gen.step()\n",
    "\n",
    "    # for batch_idx, (real, _) in enumerate(dataloader):\n",
    "    #     real = real.to(device)\n",
    "    #     noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "    #     fake = gen(noise)\n",
    "\n",
    "    #     ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "    #     disc_real = disc(real).reshape(-1)\n",
    "    #     loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "    #     disc_fake = disc(fake.detach()).reshape(-1)\n",
    "    #     loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "    #     loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "    #     disc.zero_grad()\n",
    "    #     loss_disc.backward()\n",
    "    #     opt_disc.step()\n",
    "\n",
    "    #     ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "    #     output = disc(fake).reshape(-1)\n",
    "    #     loss_gen = criterion(output, torch.ones_like(output))\n",
    "    #     gen.zero_grad()\n",
    "    #     loss_gen.backward()\n",
    "    #     opt_gen.step()\n",
    "\n",
    "    #     # Print losses occasionally and print to tensorboard\n",
    "    #     if batch_idx % 100 == 0:\n",
    "    #         print(\n",
    "    #             f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "    #               Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "    #         )\n",
    "\n",
    "    #         with torch.no_grad():\n",
    "    #             fake = gen(fixed_noise)\n",
    "    #             # take out (up to) 32 examples\n",
    "    #             img_grid_real = torchvision.utils.make_grid(\n",
    "    #                 real[:32], normalize=True\n",
    "    #             )\n",
    "    #             img_grid_fake = torchvision.utils.make_grid(\n",
    "    #                 fake[:32], normalize=True\n",
    "    #             )\n",
    "\n",
    "    #             writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "    #             writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "    #         step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
