{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from gan_model import Discriminator, Generator\n",
    "from fid_score import *\n",
    "from inception import *\n",
    "import pandas as pd\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "dev = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset = datasets.CIFAR10(root='./datasets/cifar/', train=False, download=True, transform=trans_cifar)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset, shuffle = True,batch_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test images of the chosen classes\n",
    "for img in dataloader_test:\n",
    "    x, y = img\n",
    "    chosen_imgs = []\n",
    "    for xx,yy in zip(x,y):\n",
    "        if(yy in [9,1,5,3]):\n",
    "            chosen_imgs.append(xx)\n",
    "    test_imgs=chosen_imgs\n",
    "    # test_imgs=img[0].to(dev)\n",
    "test_imgs = torch.stack(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "gen_count_to_test = 1\n",
    "file_loc = [\n",
    "'runs/2W_MIN_LOSS/models/G_epoch_199'\n",
    "# 'runs/2W_MAX_LOSS/models/G_epoch_199'\n",
    "\n",
    "# 'runs/2W_CTDC_MAX_LOSS/models/G_epoch_150',\n",
    "# 'runs/2W_CTDC_MIN_LOSS/models/G_epoch_150',\n",
    "\n",
    "# 'runs/2W_CTDC_MAX_LOSS_OVERR_1to1_same_lr/models/G_epoch_150',\n",
    "# 'runs/2W_CTDC_MIN_LOSS_OVERR_1to1_same_lr/models/G_epoch_150',\n",
    "\n",
    "# 'runs/2W_CTDC_WAVG_MAXLOSS_1to1_same_lr/models/g_EPOCH_149',\n",
    "# 'runs/2W_CTDC_WAVG_MINLOSS_1to1_same_lr/models/g_EPOCH_149',\n",
    "\n",
    "# 'runs/2W_CTDC_WAVG_MAXLOSS_1to1_diff_lr/models/g_EPOCH_150',\n",
    "# 'runs/2W_CDTC_WAVG_MAXLOSS_3to1_same_lr/models/g_EPOCH_150',\n",
    "# 'runs/2W_CTDC_WAVG_MINLOSS_2to1_same_lr/models/g_epoch_149',\n",
    "]\n",
    "assert gen_count_to_test == len(file_loc)\n",
    "\n",
    "NOISE_DIM = 128\n",
    "FID_BATCH_SIZE = 100\n",
    "fic_model = InceptionV3().to(dev)\n",
    "generators = {}\n",
    "for i in range(gen_count_to_test):\n",
    "    key = f'gen{i}'\n",
    "    generators[key] = Generator().to(dev)\n",
    "    generators[key].load_state_dict(torch.load(file_loc[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_avg = []\n",
    "for epoch in range(epochs):\n",
    "    fid_z = torch.randn(FID_BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "    random_start = np.random.randint(len(test_imgs)-FID_BATCH_SIZE)\n",
    "    for i,gen in enumerate(generators.values()):\n",
    "        if epoch == 0:\n",
    "            fid_avg.append([])\n",
    "        gen_imgs = gen(fid_z.detach())\n",
    "\n",
    "        # Save generated images\n",
    "        for j, img in enumerate(gen_imgs):\n",
    "            vutils.save_image(img, f'test/generator_imgs/gen_{i}_epoch_{j}_{epoch}.png')\n",
    "        \n",
    "        # Save real images\n",
    "        real_imgs = test_imgs[random_start:random_start+FID_BATCH_SIZE]\n",
    "        for j, img in enumerate(real_imgs):\n",
    "            vutils.save_image(img,  f'test/real_imgs/real_epoch_{j}_{epoch}.png')\n",
    "\n",
    "        # mu_gen, sigma_gen = calculate_activation_statistics(gen_imgs, fic_model, batch_size=FID_BATCH_SIZE,cuda=True)\n",
    "        # mu_test, sigma_test = calculate_activation_statistics(test_imgs[random_start:random_start+FID_BATCH_SIZE], fic_model, batch_size=FID_BATCH_SIZE,cuda=True)\n",
    "        # fid = calculate_frechet_distance(mu_gen, sigma_gen, mu_test, sigma_test)\n",
    "        # fid_avg[i].append(fid)\n",
    "        # print(f'gen#{i}/epoch#{epoch} fid_score: {fid:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_avg_np = np.array(fid_avg)\n",
    "print(fid_avg_np.mean(axis=1))\n",
    "print(fid_avg_np.std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['gen'] = [i+1 for i in range(gen_count_to_test)]\n",
    "df['mean'] = fid_avg_np.mean(axis=1).astype(int)\n",
    "df['sd'] = fid_avg_np.std(axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,len(generators)+1)\n",
    "bars = plt.bar(x,np.around(fid_avg_np.mean(axis=1)),yerr=fid_avg_np.std(axis=1),ecolor='black',capsize=10)\n",
    "plt.bar_label(bars,label_type='edge')\n",
    "plt.xticks(x)\n",
    "plt.xlabel('generator number')\n",
    "plt.ylabel('FID average')\n",
    "plt.ylim([200,240])\n",
    "# plt.savefig('{}/worker_cont.png'.format(logger.writer.logdir))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('generator-results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
