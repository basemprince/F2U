{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from dataTransformation import labels4clients, distribute_data_labels4clients\n",
    "from gan_model import Discriminator, Generator, initialize_weights\n",
    "from network import Server, Worker\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "BATCH_SIZE = 64\n",
    "NOISE_DIM = 128\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 1], 1: [0, 1], 2: [0, 1], 3: [0, 1], 4: [0, 1], 5: [0, 1], 6: [0, 1], 7: [0, 1], 8: [0, 1], 9: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "num_workers = 2\n",
    "num_unique_users = num_workers\n",
    "num_classes = 10\n",
    "classes_per_user = 10\n",
    "\n",
    "logger = Logger(model_name='F2U',data_name='CIFAR10')\n",
    "dictionary = labels4clients(num_classes,classes_per_user,num_workers,num_unique_users,False)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# trans_cifar = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.CIFAR10(root='./datasets/cifar/', train=True, download=True, transform=trans_cifar)\n",
    "dataset_test = datasets.CIFAR10(root='./datasets/cifar/', train=False, download=True, transform=trans_cifar)\n",
    "dataloader_one = torch.utils.data.DataLoader(dataset, shuffle = True,batch_size=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.data[0])\n",
    "# print(dataset.transforms(dataset.data[0],transforms.ToTensor()))\n",
    "# print(dataset.transforms(dataset.data[0],trans_cifar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
       "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
       "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
       "         ...,\n",
       "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
       "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
       "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
       "\n",
       "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
       "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
       "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
       "         ...,\n",
       "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
       "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
       "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
       "\n",
       "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
       "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
       "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
       "         ...,\n",
       "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
       "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
       "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "print(normalized)\n",
    "trans_cifar(dataset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.data.shape)\n",
    "# print(type(dataset))\n",
    "# print(dataloader_one.dataset.data.shape)\n",
    "# x,_ = dataloader_one.dataset[0]\n",
    "# print(x.shape)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized_np = np.empty((dataset.data.shape[0],dataset.data.shape[3],dataset.data.shape[1],dataset.data.shape[2]))\n",
    "for i in range(len(dataset)):\n",
    "    x_train_normalized_np[i] = trans_cifar(dataset.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(dataset.data)\n",
    "y_train = np.asarray(dataset.targets)\n",
    "x_clinet_list, y_client_list = distribute_data_labels4clients(x_train_normalized_np,y_train,dictionary,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDist(y,num_classes,user_num):\n",
    "    ax = sns.countplot(x=y)\n",
    "    ax.set(title=\"Count of data classes for %s\" %user_num)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (len(x_clinet_list)):\n",
    "    print(len(y_client_list[i]))\n",
    "    getDist(y_client_list[i],num_classes,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "dev = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netG = Generator().to(dev)\n",
    "# netD = Discriminator().to(dev)\n",
    "# summary(netG,(128,1,1))\n",
    "# summary(netD,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_server = Server(0,LEARNING_RATE)\n",
    "main_server.generator.train()\n",
    "workers = []\n",
    "for i in range(num_workers):\n",
    "    worker = Worker(i,LEARNING_RATE)\n",
    "    # x_clinet_list[i] = np.transpose(x_clinet_list[i],(0, 3, 1, 2))\n",
    "    worker.load_worker_data(x_clinet_list[i], y_client_list[i])\n",
    "    worker.discriminator.train()\n",
    "    workers.append(worker)\n",
    "    \n",
    "# summary(main_server.generator,(128,1,1))\n",
    "# summary(workers[0].discriminator,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "fixed_noise = torch.randn(36, NOISE_DIM, 1, 1).to(dev)\n",
    "\n",
    "worker_loaders = []\n",
    "\n",
    "for worker in workers:\n",
    "    # print(worker.x_data.shape)\n",
    "    worker_loaders.append([])\n",
    "    for batch_id, real in enumerate(DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE)):\n",
    "        worker_loaders[-1].append(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GAN archicture trial\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for i, data in enumerate(dataloader_one):\n",
    "#         worker = workers[0]\n",
    "#         noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "#         fake = main_server.generator(noise)\n",
    "#         real, _ = data\n",
    "\n",
    "#         ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "#         current_disc_real = worker.discriminator(real).reshape(-1)\n",
    "#         # print('current discriminator real output', current_disc_real)\n",
    "#         worker.loss_disc_real = criterion(current_disc_real, torch.ones_like(current_disc_real)*0.9)\n",
    "#         # print('worker loss_disc_real output', current_disc_real)\n",
    "#         current_disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "#         worker.loss_disc_fake = criterion(current_disc_fake, torch.ones_like(current_disc_fake)*0.1)\n",
    "#         worker.loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "#         worker.discriminator.zero_grad()\n",
    "#         worker.loss_disc.backward()\n",
    "#         # total_norm_d =0\n",
    "#         # for p in list(filter(lambda p: p.grad is not None, worker.discriminator.parameters())):\n",
    "#         #     total_norm_d += p.grad.detach().data.norm(2).item()** 2\n",
    "#         # total_norm_d = total_norm_d ** 0.5\n",
    "\n",
    "#         worker.d_optimizer.step()\n",
    "\n",
    "#         ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "#         output = worker.discriminator(fake).reshape(-1)\n",
    "#         main_server.loss_gen = criterion(output, torch.ones_like(output)*0.9)\n",
    "#         main_server.generator.zero_grad()\n",
    "#         main_server.loss_gen.backward()\n",
    "\n",
    "#         # total_norm_g =0\n",
    "#         # for p in list(filter(lambda p: p.grad is not None, main_server.generator.parameters())):\n",
    "#         #     total_norm_g += p.grad.detach().data.norm(2).item()** 2\n",
    "#         # total_norm_g = total_norm_g ** 0.5\n",
    "\n",
    "#         main_server.g_optimizer.step()\n",
    "\n",
    "\n",
    "#         logger.log(worker.loss_disc.item(),main_server.loss_gen.item(),worker.loss_disc_real, worker.loss_disc_fake,epoch,i,len(dataloader_one))\n",
    "\n",
    "#         # Print loss\n",
    "#         if i % 100 == 0:\n",
    "#             print(\n",
    "#                 f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {i}/{len(dataloader_one)} \\\n",
    "#                  Loss D: {worker.loss_disc:.4f}, loss G: {main_server.loss_gen:.4f}\"\n",
    "#             )\n",
    "#         if i% 500 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 fake = main_server.generator(fixed_noise)\n",
    "#                 logger.log_images(fake,len(fake), epoch, i, len(dataloader_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 1/782                  Loss D: 0.5021, loss G: 0.7299\n",
      "Epoch [0/50] Batch 1/782                  Loss D: 0.0318, loss G: 0.8885\n",
      "Epoch [0/50] Batch 1/782                  Loss D: 0.0199, loss G: 0.9860\n",
      "Epoch [0/50] Batch 1/782                  Loss D: 0.0241, loss G: 1.0145\n",
      "Epoch [1/50] Batch 1/782                  Loss D: 0.0215, loss G: 1.0136\n",
      "Epoch [1/50] Batch 1/782                  Loss D: 0.0275, loss G: 0.9858\n",
      "Epoch [1/50] Batch 1/782                  Loss D: 0.0244, loss G: 1.0297\n",
      "Epoch [1/50] Batch 1/782                  Loss D: 0.0216, loss G: 1.0379\n",
      "Epoch [2/50] Batch 1/782                  Loss D: 0.0263, loss G: 1.0471\n",
      "Epoch [2/50] Batch 1/782                  Loss D: 0.0234, loss G: 0.9855\n",
      "Epoch [2/50] Batch 1/782                  Loss D: 0.0265, loss G: 0.9402\n",
      "Epoch [2/50] Batch 1/782                  Loss D: 0.0203, loss G: 0.9676\n",
      "Epoch [3/50] Batch 1/782                  Loss D: 0.0205, loss G: 0.9999\n",
      "Epoch [3/50] Batch 1/782                  Loss D: 0.0340, loss G: 1.1312\n",
      "Epoch [3/50] Batch 1/782                  Loss D: 0.0331, loss G: 0.9247\n",
      "Epoch [3/50] Batch 1/782                  Loss D: 0.0297, loss G: 1.0540\n",
      "Epoch [4/50] Batch 1/782                  Loss D: 0.0263, loss G: 0.9640\n",
      "Epoch [4/50] Batch 1/782                  Loss D: 0.0628, loss G: 0.8818\n",
      "Epoch [4/50] Batch 1/782                  Loss D: 0.0496, loss G: 0.8741\n",
      "Epoch [4/50] Batch 1/782                  Loss D: 0.0838, loss G: 0.9611\n",
      "Epoch [5/50] Batch 1/782                  Loss D: 0.0602, loss G: 0.6710\n",
      "Epoch [5/50] Batch 1/782                  Loss D: 0.0402, loss G: 1.1868\n",
      "Epoch [5/50] Batch 1/782                  Loss D: 0.0346, loss G: 0.9004\n",
      "Epoch [5/50] Batch 1/782                  Loss D: 0.1104, loss G: 0.6441\n",
      "Epoch [6/50] Batch 1/782                  Loss D: 0.0491, loss G: 0.8317\n",
      "Epoch [6/50] Batch 1/782                  Loss D: 0.0741, loss G: 0.7324\n",
      "Epoch [6/50] Batch 1/782                  Loss D: 0.0880, loss G: 0.8172\n",
      "Epoch [6/50] Batch 1/782                  Loss D: 0.0535, loss G: 0.9510\n",
      "Epoch [7/50] Batch 1/782                  Loss D: 0.0894, loss G: 0.9418\n",
      "Epoch [7/50] Batch 1/782                  Loss D: 0.0687, loss G: 0.8443\n",
      "Epoch [7/50] Batch 1/782                  Loss D: 0.0908, loss G: 0.7539\n",
      "Epoch [7/50] Batch 1/782                  Loss D: 0.0734, loss G: 1.0732\n",
      "Epoch [8/50] Batch 1/782                  Loss D: 0.0403, loss G: 0.9326\n",
      "Epoch [8/50] Batch 1/782                  Loss D: 0.0768, loss G: 0.7067\n",
      "Epoch [8/50] Batch 1/782                  Loss D: 0.0821, loss G: 0.9056\n",
      "Epoch [8/50] Batch 1/782                  Loss D: 0.0587, loss G: 0.8912\n",
      "Epoch [9/50] Batch 1/782                  Loss D: 0.0393, loss G: 0.8956\n",
      "Epoch [9/50] Batch 1/782                  Loss D: 0.0436, loss G: 0.8755\n",
      "Epoch [9/50] Batch 1/782                  Loss D: 0.0592, loss G: 0.9601\n",
      "Epoch [9/50] Batch 1/782                  Loss D: 0.0465, loss G: 0.9123\n",
      "Epoch [10/50] Batch 1/782                  Loss D: 0.0856, loss G: 0.8592\n",
      "Epoch [10/50] Batch 1/782                  Loss D: 0.0441, loss G: 0.7440\n",
      "Epoch [10/50] Batch 1/782                  Loss D: 0.1031, loss G: 0.7885\n",
      "Epoch [10/50] Batch 1/782                  Loss D: 0.0550, loss G: 0.8610\n",
      "Epoch [11/50] Batch 1/782                  Loss D: 0.0468, loss G: 0.7965\n",
      "Epoch [11/50] Batch 1/782                  Loss D: 0.0461, loss G: 0.7665\n",
      "Epoch [11/50] Batch 1/782                  Loss D: 0.0459, loss G: 0.7556\n",
      "Epoch [11/50] Batch 1/782                  Loss D: 0.0422, loss G: 0.9867\n",
      "Epoch [12/50] Batch 1/782                  Loss D: 0.0426, loss G: 0.8180\n",
      "Epoch [12/50] Batch 1/782                  Loss D: 0.0622, loss G: 0.7513\n",
      "Epoch [12/50] Batch 1/782                  Loss D: 0.0466, loss G: 0.7529\n",
      "Epoch [12/50] Batch 1/782                  Loss D: 0.0824, loss G: 0.8446\n",
      "Epoch [13/50] Batch 1/782                  Loss D: 0.0466, loss G: 0.7954\n",
      "Epoch [13/50] Batch 1/782                  Loss D: 0.0809, loss G: 0.7217\n",
      "Epoch [13/50] Batch 1/782                  Loss D: 0.0735, loss G: 1.0304\n",
      "Epoch [13/50] Batch 1/782                  Loss D: 0.0680, loss G: 1.0812\n",
      "Epoch [14/50] Batch 1/782                  Loss D: 0.0355, loss G: 0.9324\n",
      "Epoch [14/50] Batch 1/782                  Loss D: 0.0429, loss G: 0.9089\n",
      "Epoch [14/50] Batch 1/782                  Loss D: 0.0630, loss G: 0.9806\n",
      "Epoch [14/50] Batch 1/782                  Loss D: 0.0559, loss G: 0.8433\n",
      "Epoch [15/50] Batch 1/782                  Loss D: 0.0556, loss G: 1.1008\n",
      "Epoch [15/50] Batch 1/782                  Loss D: 0.0404, loss G: 0.8213\n",
      "Epoch [15/50] Batch 1/782                  Loss D: 0.0595, loss G: 0.9689\n",
      "Epoch [15/50] Batch 1/782                  Loss D: 0.0420, loss G: 1.0972\n",
      "Epoch [16/50] Batch 1/782                  Loss D: 0.0548, loss G: 0.8393\n",
      "Epoch [16/50] Batch 1/782                  Loss D: 0.1029, loss G: 0.7769\n",
      "Epoch [16/50] Batch 1/782                  Loss D: 0.0535, loss G: 0.8314\n",
      "Epoch [16/50] Batch 1/782                  Loss D: 0.1037, loss G: 0.9718\n",
      "Epoch [17/50] Batch 1/782                  Loss D: 0.1294, loss G: 1.1612\n",
      "Epoch [17/50] Batch 1/782                  Loss D: 0.0590, loss G: 0.9543\n",
      "Epoch [17/50] Batch 1/782                  Loss D: 0.0731, loss G: 0.7813\n",
      "Epoch [17/50] Batch 1/782                  Loss D: 0.0514, loss G: 1.0302\n",
      "Epoch [18/50] Batch 1/782                  Loss D: 0.0387, loss G: 0.8699\n",
      "Epoch [18/50] Batch 1/782                  Loss D: 0.0644, loss G: 0.9586\n",
      "Epoch [18/50] Batch 1/782                  Loss D: 0.0807, loss G: 0.8756\n",
      "Epoch [18/50] Batch 1/782                  Loss D: 0.0701, loss G: 0.9112\n",
      "Epoch [19/50] Batch 1/782                  Loss D: 0.0833, loss G: 0.8183\n",
      "Epoch [19/50] Batch 1/782                  Loss D: 0.0478, loss G: 0.8441\n",
      "Epoch [19/50] Batch 1/782                  Loss D: 0.0684, loss G: 0.8226\n",
      "Epoch [19/50] Batch 1/782                  Loss D: 0.0467, loss G: 0.9506\n",
      "Epoch [20/50] Batch 1/782                  Loss D: 0.0652, loss G: 0.9686\n",
      "Epoch [20/50] Batch 1/782                  Loss D: 0.0968, loss G: 0.9256\n",
      "Epoch [20/50] Batch 1/782                  Loss D: 0.0569, loss G: 0.8762\n",
      "Epoch [20/50] Batch 1/782                  Loss D: 0.0560, loss G: 0.8047\n",
      "Epoch [21/50] Batch 1/782                  Loss D: 0.0643, loss G: 1.1304\n",
      "Epoch [21/50] Batch 1/782                  Loss D: 0.0499, loss G: 0.9571\n",
      "Epoch [21/50] Batch 1/782                  Loss D: 0.1359, loss G: 0.6609\n",
      "Epoch [21/50] Batch 1/782                  Loss D: 0.0909, loss G: 1.0555\n",
      "Epoch [22/50] Batch 1/782                  Loss D: 0.0859, loss G: 0.9195\n",
      "Epoch [22/50] Batch 1/782                  Loss D: 0.0886, loss G: 0.8578\n",
      "Epoch [22/50] Batch 1/782                  Loss D: 0.0607, loss G: 1.1768\n",
      "Epoch [22/50] Batch 1/782                  Loss D: 0.0347, loss G: 0.8602\n",
      "Epoch [23/50] Batch 1/782                  Loss D: 0.0553, loss G: 0.8761\n",
      "Epoch [23/50] Batch 1/782                  Loss D: 0.0857, loss G: 0.7838\n",
      "Epoch [23/50] Batch 1/782                  Loss D: 0.0641, loss G: 0.8805\n",
      "Epoch [23/50] Batch 1/782                  Loss D: 0.0413, loss G: 1.0317\n",
      "Epoch [24/50] Batch 1/782                  Loss D: 0.0663, loss G: 0.8141\n",
      "Epoch [24/50] Batch 1/782                  Loss D: 0.0782, loss G: 1.1504\n",
      "Epoch [24/50] Batch 1/782                  Loss D: 0.1042, loss G: 0.8642\n",
      "Epoch [24/50] Batch 1/782                  Loss D: 0.0752, loss G: 0.8628\n",
      "Epoch [25/50] Batch 1/782                  Loss D: 0.0600, loss G: 1.2597\n",
      "Epoch [25/50] Batch 1/782                  Loss D: 0.0798, loss G: 0.8895\n",
      "Epoch [25/50] Batch 1/782                  Loss D: 0.0748, loss G: 0.8938\n",
      "Epoch [25/50] Batch 1/782                  Loss D: 0.0810, loss G: 0.8993\n",
      "Epoch [26/50] Batch 1/782                  Loss D: 0.0759, loss G: 0.8923\n",
      "Epoch [26/50] Batch 1/782                  Loss D: 0.0856, loss G: 0.7841\n",
      "Epoch [26/50] Batch 1/782                  Loss D: 0.0824, loss G: 0.8223\n",
      "Epoch [26/50] Batch 1/782                  Loss D: 0.0877, loss G: 0.7448\n",
      "Epoch [27/50] Batch 1/782                  Loss D: 0.0416, loss G: 0.9185\n",
      "Epoch [27/50] Batch 1/782                  Loss D: 0.0570, loss G: 0.9722\n",
      "Epoch [27/50] Batch 1/782                  Loss D: 0.1025, loss G: 0.7911\n",
      "Epoch [27/50] Batch 1/782                  Loss D: 0.1151, loss G: 0.7913\n",
      "Epoch [28/50] Batch 1/782                  Loss D: 0.0645, loss G: 1.0709\n",
      "Epoch [28/50] Batch 1/782                  Loss D: 0.0987, loss G: 0.8361\n",
      "Epoch [28/50] Batch 1/782                  Loss D: 0.0741, loss G: 0.8389\n",
      "Epoch [28/50] Batch 1/782                  Loss D: 0.0554, loss G: 1.0233\n",
      "Epoch [29/50] Batch 1/782                  Loss D: 0.1158, loss G: 1.0598\n",
      "Epoch [29/50] Batch 1/782                  Loss D: 0.0638, loss G: 1.0696\n",
      "Epoch [29/50] Batch 1/782                  Loss D: 0.0775, loss G: 0.7463\n",
      "Epoch [29/50] Batch 1/782                  Loss D: 0.0676, loss G: 0.9269\n",
      "Epoch [30/50] Batch 1/782                  Loss D: 0.0662, loss G: 0.8279\n",
      "Epoch [30/50] Batch 1/782                  Loss D: 0.0859, loss G: 0.9396\n",
      "Epoch [30/50] Batch 1/782                  Loss D: 0.1280, loss G: 0.8738\n",
      "Epoch [30/50] Batch 1/782                  Loss D: 0.0701, loss G: 0.9912\n",
      "Epoch [31/50] Batch 1/782                  Loss D: 0.1266, loss G: 0.6855\n",
      "Epoch [31/50] Batch 1/782                  Loss D: 0.0782, loss G: 0.7740\n",
      "Epoch [31/50] Batch 1/782                  Loss D: 0.0652, loss G: 0.9338\n",
      "Epoch [31/50] Batch 1/782                  Loss D: 0.1413, loss G: 0.7657\n",
      "Epoch [32/50] Batch 1/782                  Loss D: 0.0884, loss G: 1.0226\n",
      "Epoch [32/50] Batch 1/782                  Loss D: 0.0785, loss G: 1.2040\n",
      "Epoch [32/50] Batch 1/782                  Loss D: 0.1092, loss G: 0.8290\n",
      "Epoch [32/50] Batch 1/782                  Loss D: 0.0642, loss G: 0.9149\n",
      "Epoch [33/50] Batch 1/782                  Loss D: 0.0824, loss G: 0.8129\n",
      "Epoch [33/50] Batch 1/782                  Loss D: 0.0796, loss G: 0.8272\n",
      "Epoch [33/50] Batch 1/782                  Loss D: 0.1233, loss G: 0.6315\n",
      "Epoch [33/50] Batch 1/782                  Loss D: 0.0743, loss G: 1.0478\n",
      "Epoch [34/50] Batch 1/782                  Loss D: 0.0854, loss G: 0.9917\n",
      "Epoch [34/50] Batch 1/782                  Loss D: 0.1040, loss G: 0.8032\n",
      "Epoch [34/50] Batch 1/782                  Loss D: 0.0726, loss G: 0.7550\n",
      "Epoch [34/50] Batch 1/782                  Loss D: 0.1191, loss G: 0.6973\n",
      "Epoch [35/50] Batch 1/782                  Loss D: 0.1108, loss G: 0.9358\n",
      "Epoch [35/50] Batch 1/782                  Loss D: 0.0642, loss G: 0.8416\n",
      "Epoch [35/50] Batch 1/782                  Loss D: 0.0549, loss G: 0.9122\n",
      "Epoch [35/50] Batch 1/782                  Loss D: 0.0929, loss G: 1.0190\n",
      "Epoch [36/50] Batch 1/782                  Loss D: 0.0605, loss G: 0.8947\n",
      "Epoch [36/50] Batch 1/782                  Loss D: 0.0853, loss G: 0.9180\n",
      "Epoch [36/50] Batch 1/782                  Loss D: 0.0925, loss G: 0.9270\n",
      "Epoch [36/50] Batch 1/782                  Loss D: 0.1156, loss G: 0.7941\n",
      "Epoch [37/50] Batch 1/782                  Loss D: 0.0896, loss G: 0.6169\n",
      "Epoch [37/50] Batch 1/782                  Loss D: 0.0808, loss G: 0.8429\n",
      "Epoch [37/50] Batch 1/782                  Loss D: 0.1971, loss G: 0.6545\n",
      "Epoch [37/50] Batch 1/782                  Loss D: 0.0866, loss G: 0.7696\n",
      "Epoch [38/50] Batch 1/782                  Loss D: 0.1465, loss G: 0.8441\n",
      "Epoch [38/50] Batch 1/782                  Loss D: 0.0651, loss G: 0.9141\n",
      "Epoch [38/50] Batch 1/782                  Loss D: 0.0784, loss G: 0.7910\n",
      "Epoch [38/50] Batch 1/782                  Loss D: 0.0654, loss G: 0.9552\n",
      "Epoch [39/50] Batch 1/782                  Loss D: 0.1032, loss G: 0.6198\n",
      "Epoch [39/50] Batch 1/782                  Loss D: 0.1099, loss G: 0.8463\n",
      "Epoch [39/50] Batch 1/782                  Loss D: 0.0615, loss G: 0.8902\n",
      "Epoch [39/50] Batch 1/782                  Loss D: 0.1069, loss G: 0.5715\n",
      "Epoch [40/50] Batch 1/782                  Loss D: 0.0873, loss G: 0.9326\n",
      "Epoch [40/50] Batch 1/782                  Loss D: 0.0887, loss G: 0.8283\n",
      "Epoch [40/50] Batch 1/782                  Loss D: 0.0800, loss G: 0.8547\n",
      "Epoch [40/50] Batch 1/782                  Loss D: 0.0619, loss G: 0.7535\n",
      "Epoch [41/50] Batch 1/782                  Loss D: 0.0702, loss G: 0.9326\n",
      "Epoch [41/50] Batch 1/782                  Loss D: 0.1086, loss G: 0.6776\n",
      "Epoch [41/50] Batch 1/782                  Loss D: 0.1164, loss G: 0.8393\n",
      "Epoch [41/50] Batch 1/782                  Loss D: 0.0894, loss G: 1.0972\n",
      "Epoch [42/50] Batch 1/782                  Loss D: 0.0767, loss G: 0.7302\n",
      "Epoch [42/50] Batch 1/782                  Loss D: 0.0859, loss G: 0.7222\n",
      "Epoch [42/50] Batch 1/782                  Loss D: 0.1101, loss G: 0.9547\n",
      "Epoch [42/50] Batch 1/782                  Loss D: 0.0611, loss G: 0.9112\n",
      "Epoch [43/50] Batch 1/782                  Loss D: 0.0746, loss G: 0.7828\n",
      "Epoch [43/50] Batch 1/782                  Loss D: 0.1265, loss G: 0.6226\n",
      "Epoch [43/50] Batch 1/782                  Loss D: 0.0770, loss G: 0.9960\n",
      "Epoch [43/50] Batch 1/782                  Loss D: 0.0822, loss G: 0.9005\n",
      "Epoch [44/50] Batch 1/782                  Loss D: 0.1088, loss G: 0.7612\n",
      "Epoch [44/50] Batch 1/782                  Loss D: 0.0976, loss G: 0.7012\n",
      "Epoch [44/50] Batch 1/782                  Loss D: 0.0981, loss G: 0.7716\n",
      "Epoch [44/50] Batch 1/782                  Loss D: 0.0800, loss G: 0.6722\n",
      "Epoch [45/50] Batch 1/782                  Loss D: 0.0647, loss G: 0.7241\n",
      "Epoch [45/50] Batch 1/782                  Loss D: 0.0580, loss G: 0.8817\n",
      "Epoch [45/50] Batch 1/782                  Loss D: 0.0685, loss G: 0.7512\n",
      "Epoch [45/50] Batch 1/782                  Loss D: 0.0642, loss G: 0.7134\n",
      "Epoch [46/50] Batch 1/782                  Loss D: 0.0603, loss G: 0.7848\n",
      "Epoch [46/50] Batch 1/782                  Loss D: 0.0916, loss G: 0.9290\n",
      "Epoch [46/50] Batch 1/782                  Loss D: 0.0578, loss G: 0.5371\n",
      "Epoch [46/50] Batch 1/782                  Loss D: 0.0886, loss G: 0.5178\n",
      "Epoch [47/50] Batch 1/782                  Loss D: 0.0688, loss G: 0.5167\n",
      "Epoch [47/50] Batch 1/782                  Loss D: 0.0415, loss G: 0.9018\n",
      "Epoch [47/50] Batch 1/782                  Loss D: 0.0503, loss G: 0.6723\n",
      "Epoch [47/50] Batch 1/782                  Loss D: 0.0618, loss G: 0.7119\n",
      "Epoch [48/50] Batch 1/782                  Loss D: 0.0474, loss G: 0.8805\n",
      "Epoch [48/50] Batch 1/782                  Loss D: 0.0437, loss G: 0.8320\n",
      "Epoch [48/50] Batch 1/782                  Loss D: 0.0534, loss G: 0.8364\n",
      "Epoch [48/50] Batch 1/782                  Loss D: 0.0421, loss G: 0.7214\n",
      "Epoch [49/50] Batch 1/782                  Loss D: 0.0319, loss G: 0.5801\n",
      "Epoch [49/50] Batch 1/782                  Loss D: 0.0521, loss G: 0.3721\n",
      "Epoch [49/50] Batch 1/782                  Loss D: 0.0374, loss G: 0.7504\n",
      "Epoch [49/50] Batch 1/782                  Loss D: 0.0396, loss G: 0.8113\n"
     ]
    }
   ],
   "source": [
    "# main training loop for F2U\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_id in range(len(worker_loaders[0])):\n",
    "\n",
    "        highest_loss = 0\n",
    "        chosen_discriminator = None\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "        fake = main_server.generator(noise)\n",
    "\n",
    "        for worker_id, worker in enumerate(workers):\n",
    "            current_worker_real = worker_loaders[worker_id][batch_id].float().to(dev)\n",
    "            # print(real.shape)\n",
    "\n",
    "            ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "            current_disc_real = worker.discriminator(current_worker_real).reshape(-1)\n",
    "            worker.loss_disc_real = criterion(current_disc_real, torch.ones_like(current_disc_real))\n",
    "            current_disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "            worker.loss_disc_fake = criterion(current_disc_fake, torch.zeros_like(current_disc_fake))\n",
    "            worker.loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "            worker.discriminator.zero_grad()\n",
    "            worker.loss_disc.backward()\n",
    "            worker.d_optimizer.step()\n",
    "            # print(worker.loss_disc_fake, i)\n",
    "            if highest_loss < worker.loss_disc_fake:\n",
    "                highest_loss = worker.loss_disc_fake\n",
    "                chosen_discriminator = worker_id\n",
    "        # print(f\"chosen worker is {chosen_discriminator} with loss of: {highest_loss.item():.4f}\")\n",
    "        chosen_worker = workers[chosen_discriminator]\n",
    "        \n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = chosen_worker.discriminator(fake).reshape(-1)\n",
    "        main_server.loss_gen = criterion(output, torch.ones_like(output))\n",
    "        main_server.generator.zero_grad()\n",
    "        main_server.loss_gen.backward()\n",
    "        main_server.g_optimizer.step()\n",
    "\n",
    "        logger.log(chosen_worker.loss_disc.item(),main_server.loss_gen.item(),chosen_worker.loss_disc_real, chosen_worker.loss_disc_fake,epoch,batch_id,len(worker_loaders[0]))\n",
    "\n",
    "        # Print loss\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_id}/{len(worker_loaders[0])} \\\n",
    "                 Loss D: {chosen_worker.loss_disc:.4f}, loss G: {main_server.loss_gen:.4f}\"\n",
    "            )\n",
    "        if batch_id% 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = main_server.generator(fixed_noise)\n",
    "                logger.log_images(fake,len(fake), epoch, batch_id, len(worker_loaders[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = []\n",
    "\n",
    "# for worker in workers:\n",
    "#     # print(worker.x_data.shape)\n",
    "#     dataloaders.append(DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE))\n",
    "\n",
    "# i = iter(dataloaders[0])\n",
    "# print(next(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "# NOISE_DIM = 128\n",
    "# fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(dev)\n",
    "# writer_real = SummaryWriter(f\"logs/real\")\n",
    "# writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "# step = 0\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     highest_loss = 0\n",
    "#     chosen_discriminator = None\n",
    "#     for i, worker in enumerate(workers):\n",
    "#         print(worker.x_data.shape)\n",
    "#         dataloader = DataLoader(dataset=worker.x_data,batch_size=BATCH_SIZE)\n",
    "#         for batch_id, real in enumerate(dataloader):\n",
    "#             real = real.float().to(dev)\n",
    "#             # print(real.shape)\n",
    "#             # print(real)\n",
    "#             noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1,1).to(dev)\n",
    "#             fake = main_server.generator(noise)\n",
    "\n",
    "#             ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "#             disc_real = worker.discriminator(real).reshape(-1)\n",
    "#             worker.loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "#             disc_fake = worker.discriminator(fake.detach()).reshape(-1)\n",
    "#             worker.loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "#             loss_disc = (worker.loss_disc_real + worker.loss_disc_fake) / 2\n",
    "#             worker.discriminator.zero_grad()\n",
    "#             loss_disc.backward()\n",
    "#             worker.d_optimizer.step()\n",
    "#             if batch_id % 20 == 0:\n",
    "#                 print(\n",
    "#                     f\"Worker: {i} Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_id}/{len(dataloader)} \\\n",
    "#                         Loss D: {loss_disc:.4f}\"\n",
    "#                 )\n",
    "#         # print(worker.loss_disc_fake, i)\n",
    "#         if highest_loss < worker.loss_disc_fake:\n",
    "#             highest_loss = worker.loss_disc_fake\n",
    "#             chosen_discriminator = i\n",
    "#         print(f\"chosen worker is {chosen_discriminator} with loss of: {highest_loss.item()}\")\n",
    "#     dataloader = DataLoader(dataset=workers[chosen_discriminator].x_data,batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "    # output = disc(fake).reshape(-1)\n",
    "    # loss_gen = criterion(output, torch.ones_like(output))\n",
    "    # gen.zero_grad()\n",
    "    # loss_gen.backward()\n",
    "    # opt_gen.step()\n",
    "\n",
    "    # for batch_idx, (real, _) in enumerate(dataloader):\n",
    "    #     real = real.to(device)\n",
    "    #     noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "    #     fake = gen(noise)\n",
    "\n",
    "    #     ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "    #     disc_real = disc(real).reshape(-1)\n",
    "    #     loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "    #     disc_fake = disc(fake.detach()).reshape(-1)\n",
    "    #     loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "    #     loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "    #     disc.zero_grad()\n",
    "    #     loss_disc.backward()\n",
    "    #     opt_disc.step()\n",
    "\n",
    "    #     ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "    #     output = disc(fake).reshape(-1)\n",
    "    #     loss_gen = criterion(output, torch.ones_like(output))\n",
    "    #     gen.zero_grad()\n",
    "    #     loss_gen.backward()\n",
    "    #     opt_gen.step()\n",
    "\n",
    "    #     # Print losses occasionally and print to tensorboard\n",
    "    #     if batch_idx % 100 == 0:\n",
    "    #         print(\n",
    "    #             f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "    #               Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "    #         )\n",
    "\n",
    "    #         with torch.no_grad():\n",
    "    #             fake = gen(fixed_noise)\n",
    "    #             # take out (up to) 32 examples\n",
    "    #             img_grid_real = torchvision.utils.make_grid(\n",
    "    #                 real[:32], normalize=True\n",
    "    #             )\n",
    "    #             img_grid_fake = torchvision.utils.make_grid(\n",
    "    #                 fake[:32], normalize=True\n",
    "    #             )\n",
    "\n",
    "    #             writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "    #             writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "    #         step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
